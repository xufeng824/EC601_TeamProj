# EC601_TeamProj
This is the final team project for BU EC601

## Project Description
Our project is aim to build an App which can help the blind avoid obstacles.
The app basically can do the detection, measurment, alart functions.

## Tools we used
Swift -- The language to develop IOS app(I wrote a test file which is SwiftTest01)<br>
ARKit -- Developed by Apple which provides us the access to using Lidar, and Iphone camera.<br>
CoreML -- Developed by Apple which is a combination of machine learning models.

## Algorithms we compared
YOLO„ÄÅ


## Example
Here is an example of mobile YOLO which is from https://github.com/tucan9389/ObjectDetection-CoreML#trained-dataset-infos

<img src="https://user-images.githubusercontent.com/48322294/198395458-f4eb4a53-bc7c-4415-b38c-f8db70121ff8.PNG" width ="40%">


## UI of the App

When the distance less than one close value
![WechatIMG30609](https://user-images.githubusercontent.com/48322294/206728828-87798c6c-0c16-430b-b607-5352d69dbbfd.png)


Detect the distance

![WechatIMG30608](https://user-images.githubusercontent.com/48322294/206728852-1df6417b-8e0a-4fb0-9183-64105a367797.png)

