# EC601_TeamProj
This is the final team project for BU EC601

## Project Description
Our project is aim to build an App which can help the blind avoid obstacles.
The app basically can do the detection, measurment, alart functions.

## Tools we used
Swift -- The language to develop IOS app(I wrote a test file which is SwiftTest01)<br>
ARKit -- Developed by Apple which provides us the access to using Lidar, and Iphone camera.<br>
CoreML -- Developed by Apple which is a combination of machine learning models.

## Algorithms we compared
YOLO„ÄÅ


## Example
Here is an example of mobile YOLO which is from https://github.com/tucan9389/ObjectDetection-CoreML#trained-dataset-infos

<img src="https://user-images.githubusercontent.com/48322294/198395458-f4eb4a53-bc7c-4415-b38c-f8db70121ff8.PNG" width ="40%">


## UI of the App

When the distance less than one close value
<img src="![WechatIMG30609](https://user-images.githubusercontent.com/48322294/206728594-ce353486-7c5d-4292-9ae0-a7ff3d202de7.png" width="40%")

Detect the distance

![WechatIMG30608](https://user-images.githubusercontent.com/48322294/206728059-7f6b9ea0-3da2-4864-a313-174538a8dd54.png width ="40%")
